{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "#nltk.download('punkt')\n",
    "import os\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 : Creating a function to remove stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There has been confusion in how to find stop words, since there been vague mentioning of the sources, for different purposes, in project's text files. Hence, I am going to make a function in which user will be able to choose whichever way to remove stopwords, they like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>USING MASTER DICTIONARY</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dict_ini = pd.read_excel('LoughranMcDonald_MasterDictionary_2018.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = master_dict_ini.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Sequence Number</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Word Proportion</th>\n",
       "      <th>Average Proportion</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Doc Count</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Constraining</th>\n",
       "      <th>Superfluous</th>\n",
       "      <th>Interesting</th>\n",
       "      <th>Modal</th>\n",
       "      <th>Irr_Verb</th>\n",
       "      <th>Harvard_IV</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AARDVARK</td>\n",
       "      <td>1</td>\n",
       "      <td>277</td>\n",
       "      <td>1.480368e-08</td>\n",
       "      <td>1.239377e-08</td>\n",
       "      <td>3.564730e-06</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AARDVARKS</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.603287e-10</td>\n",
       "      <td>9.725110e-12</td>\n",
       "      <td>9.863549e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABACI</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4.275431e-10</td>\n",
       "      <td>1.386497e-10</td>\n",
       "      <td>6.225591e-08</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABACK</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>6.413147e-10</td>\n",
       "      <td>3.159061e-10</td>\n",
       "      <td>9.383557e-08</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABACUS</td>\n",
       "      <td>5</td>\n",
       "      <td>7250</td>\n",
       "      <td>3.874610e-07</td>\n",
       "      <td>3.681624e-07</td>\n",
       "      <td>3.366553e-05</td>\n",
       "      <td>914</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86481</th>\n",
       "      <td>ZYGOTE</td>\n",
       "      <td>86482</td>\n",
       "      <td>46</td>\n",
       "      <td>2.458373e-09</td>\n",
       "      <td>9.686336e-10</td>\n",
       "      <td>2.064395e-07</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86482</th>\n",
       "      <td>ZYGOTES</td>\n",
       "      <td>86483</td>\n",
       "      <td>1</td>\n",
       "      <td>5.344289e-11</td>\n",
       "      <td>2.041851e-11</td>\n",
       "      <td>2.070917e-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86483</th>\n",
       "      <td>ZYGOTIC</td>\n",
       "      <td>86484</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86484</th>\n",
       "      <td>ZYMURGIES</td>\n",
       "      <td>86485</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86485</th>\n",
       "      <td>ZYMURGY</td>\n",
       "      <td>86486</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86486 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  Sequence Number  Word Count  Word Proportion  \\\n",
       "0       AARDVARK                1         277     1.480368e-08   \n",
       "1      AARDVARKS                2           3     1.603287e-10   \n",
       "2          ABACI                3           8     4.275431e-10   \n",
       "3          ABACK                4          12     6.413147e-10   \n",
       "4         ABACUS                5        7250     3.874610e-07   \n",
       "...          ...              ...         ...              ...   \n",
       "86481     ZYGOTE            86482          46     2.458373e-09   \n",
       "86482    ZYGOTES            86483           1     5.344289e-11   \n",
       "86483    ZYGOTIC            86484           0     0.000000e+00   \n",
       "86484  ZYMURGIES            86485           0     0.000000e+00   \n",
       "86485    ZYMURGY            86486           0     0.000000e+00   \n",
       "\n",
       "       Average Proportion       Std Dev  Doc Count  Negative  Positive  \\\n",
       "0            1.239377e-08  3.564730e-06         84         0         0   \n",
       "1            9.725110e-12  9.863549e-09          1         0         0   \n",
       "2            1.386497e-10  6.225591e-08          7         0         0   \n",
       "3            3.159061e-10  9.383557e-08         12         0         0   \n",
       "4            3.681624e-07  3.366553e-05        914         0         0   \n",
       "...                   ...           ...        ...       ...       ...   \n",
       "86481        9.686336e-10  2.064395e-07         31         0         0   \n",
       "86482        2.041851e-11  2.070917e-08          1         0         0   \n",
       "86483        0.000000e+00  0.000000e+00          0         0         0   \n",
       "86484        0.000000e+00  0.000000e+00          0         0         0   \n",
       "86485        0.000000e+00  0.000000e+00          0         0         0   \n",
       "\n",
       "       Uncertainty  Litigious  Constraining  Superfluous  Interesting  Modal  \\\n",
       "0                0          0             0            0            0      0   \n",
       "1                0          0             0            0            0      0   \n",
       "2                0          0             0            0            0      0   \n",
       "3                0          0             0            0            0      0   \n",
       "4                0          0             0            0            0      0   \n",
       "...            ...        ...           ...          ...          ...    ...   \n",
       "86481            0          0             0            0            0      0   \n",
       "86482            0          0             0            0            0      0   \n",
       "86483            0          0             0            0            0      0   \n",
       "86484            0          0             0            0            0      0   \n",
       "86485            0          0             0            0            0      0   \n",
       "\n",
       "       Irr_Verb  Harvard_IV  Syllables     Source  \n",
       "0             0           0          2  12of12inf  \n",
       "1             0           0          2  12of12inf  \n",
       "2             0           0          3  12of12inf  \n",
       "3             0           0          2  12of12inf  \n",
       "4             0           0          3  12of12inf  \n",
       "...         ...         ...        ...        ...  \n",
       "86481         0           0          2  12of12inf  \n",
       "86482         0           0          2  12of12inf  \n",
       "86483         0           0          3  12of12inf  \n",
       "86484         0           0          3  12of12inf  \n",
       "86485         0           0          3  12of12inf  \n",
       "\n",
       "[86486 rows x 19 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "md['Word'] = md['Word'].apply(lambda x: str(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_keep = list(md['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_keep.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86486"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_to_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>STOPWORDS FROM THE GIVEN WEBSITE</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "stop_word_file_path = '/home/pramila/Desktop/CLASSWORK/ML-ASGN-BLACKCOFFER/blackcoffer assignment/STOP-WORDS/'\n",
    "\n",
    "list_of_files = os.listdir(stop_word_file_path)\n",
    "\n",
    "#2\n",
    "for i in list_of_files:\n",
    "    \n",
    "    with open(os.path.join(stop_word_file_path, i), 'r') as words :\n",
    "        \n",
    "        content = words.read()\n",
    "        \n",
    "        with open('stop_words.txt', 'a+') as stop_words :\n",
    "            \n",
    "            stop_words.write(content + '\\n')\n",
    "            \n",
    "            \n",
    "#3\n",
    "with open('stop_words.txt', 'r') as stop_words :\n",
    "            \n",
    "            list_of_stop_words = stop_words.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_of_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some modification req in stop_words_list\n",
    "\n",
    "for i in range(len(list_of_stop_words)) :\n",
    "    \n",
    "    list_of_stop_words[i] = list_of_stop_words[i].replace('\\n', \"\").lower()\n",
    "\n",
    "\n",
    "list_of_stop_words = list(set(list_of_stop_words))\n",
    "\n",
    "list_of_stop_words.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>STOPWORDS FROM NLTK MODULE</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>THE FUNCTION</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODE parameter states which way you want to find stop words\n",
    "# MODE = 0 : stopwords from website\n",
    "# MODE = 1 : stopwords from nltk library\n",
    "# MODE = 2 : using master dictionary\n",
    "\n",
    "def remove_stop_words(content, MODE=0):\n",
    "    \n",
    "    filtered_words = []\n",
    "    \n",
    "    if MODE == 0 :\n",
    "        \n",
    "        for i in content:\n",
    "\n",
    "            if i not in list_of_stop_words:\n",
    "\n",
    "                filtered_words.append(i)\n",
    "            \n",
    "    \n",
    "        return filtered_words\n",
    "    \n",
    "    if MODE == 1 :\n",
    "        \n",
    "        for i in content:\n",
    "\n",
    "            if i not in stop_words:\n",
    "\n",
    "                filtered_words.append(i)\n",
    "                \n",
    "        return filtered_words\n",
    "    \n",
    "    if MODE == 2 :\n",
    "        \n",
    "        for i in content:\n",
    "            \n",
    "            if i in words_to_keep:\n",
    "                \n",
    "                filtered_words.append(i)\n",
    "                \n",
    "        return filtered_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 : Extracting the (textual data + related variables) we need, from each financial report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2A - preparing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -c anaconda xlrd --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_report_ini_data = pd.read_excel('cik_list.xlsx') #original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_rep_data = financial_report_ini_data.copy() #copying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_rep_data['SECFNAME'] = 'https://www.sec.gov/Archives/' + fin_rep_data['SECFNAME'] #modifying the column F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#fin_rep_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2B - modifying FDATE column's datastructure, for better use of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fin_rep_data.loc[0, 'FDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_rep_data['FDATE'] = fin_rep_data['FDATE'].apply(lambda x : datetime.date(x.year,x.month,x.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(fin_rep_data.loc[0, 'FDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fin_rep_data.loc[0, 'FDATE'].year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2C - extracting section wise informations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>EXTRACTING CONTENT FROM URLS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = defaultdict(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in fin_rep_data.index:\n",
    "    \n",
    "    url[i] = fin_rep_data.loc[i, 'SECFNAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>SECTIONS TO LOOK FOR</b> : Management's Discussion and Analysis, Quantitative and Qualitative Disclosures about Market Risk, Risk Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_patterns = [\n",
    "    r'''(ITEM\\s.\\.\\sMANAGEMENTS\\sDISCUSSION\\sAND\\sANALYSIS\\sOF\\sFINANCIAL\\sCONDITION\\sAND\\sRESULTS)(.*?)(ITEM\\s\\d\\.\\s)''', \n",
    "    r'''(ITEM\\s.\\.\\sQUANTITATIVE\\sAND\\sQUALITATIVE\\sDISCLOSURES\\sABOUT\\sMARKET\\sRISK)(.*?)(ITEM\\s.\\.\\s)''',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>FUNCTIONS FOR MODIFICATIONS & GETTING VARIABLES' VALUES IN-HAND:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_file_content(l):\n",
    "    \n",
    "    #l will the list of lines in file and function returns a full content in form of single string\n",
    "    \n",
    "    for i in range(len(content)):\n",
    "        l[i] = l[i].replace('\\n', ' ')\n",
    "        l[i] = l[i].replace('\\\\', '')\n",
    "        l[i] = l[i].replace('\\t', ' ')\n",
    "        l[i] = l[i].replace(\"\\'\", '')\n",
    "    \n",
    "    new_str = ' '.join(l)\n",
    "    \n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(actual_content):\n",
    "    \n",
    "    # 1. UNNECCESSARY CHARACTERS REMOVAL\n",
    "    \n",
    "    actual_content = re.sub(r\"(<.*>)\",r\" \",actual_content).lower()\n",
    "    \n",
    "    actual_content = re.sub(\"[^a-zA-Z]\",\" \",actual_content).lower()\n",
    "\n",
    "    actual_content = re.sub(r'\\s+', r' ', actual_content).lower() \n",
    "    \n",
    "    # 2. REMOVING STOP WORDS\n",
    "    \n",
    "    actual_content = list(set(actual_content.split()))\n",
    "        \n",
    "    actual_content = remove_stop_words(actual_content, MODE=0)\n",
    "    \n",
    "    return actual_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def section_content_info(content_string, pattern):\n",
    "    \n",
    "    temp_list = re.findall(pattern, content_string, re.M)\n",
    "    \n",
    "    if len(temp_list) != 0 :\n",
    "\n",
    "        actual_content = temp_list[0][1]\n",
    "\n",
    "                        #actual_content = re.sub(r\"(<.*>)\",r\" \",actual_content).lower()\n",
    "\n",
    "        number_of_sentences = len(sent_tokenize(actual_content))\n",
    "        \n",
    "        # NOW: changing the string - removing stop words, counting the number of words and tokenizing the string \n",
    "\n",
    "                            # 1. UNNECCESSARY CHARACTERS REMOVAL\n",
    "\n",
    "                            #actual_content = re.sub(\"[^a-zA-Z]\",\" \",actual_content).lower()\n",
    "\n",
    "                            #actual_content = re.sub(r'\\s+', r' ', actual_content).lower()  \n",
    "                            # 2. REMOVING STOP WORDS\n",
    "\n",
    "                            #         actual_content = list(set(actual_content.split()))\n",
    "        \n",
    "                            #         actual_content = remove_stop_words(actual_content, MODE=0)\n",
    "    \n",
    "        \n",
    "        actual_content = clean(actual_content)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 3. NLTK TOKENIZER\n",
    "\n",
    "        #    IT CAN NOTED THAT OUR TEXT STRING IS TOKENIZED UPTILL NOW\n",
    "        #    WE DON'T NEED NLTK TOKENIZER, BUT STILL, JUST IN CASE WE\n",
    "        #    HAVE MISSED SOMETHING, NLTK TOKENIZER WILL HANDLE THAT !\n",
    "\n",
    "        actual_content = ' '.join(actual_content)\n",
    "\n",
    "        final_words = word_tokenize(actual_content)\n",
    "\n",
    "        return [[final_words], number_of_sentences]\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting uncertain and constraining words \n",
    "\n",
    "uw_initial = pd.read_excel('uncertainty_dictionary.xlsx')\n",
    "cons_initial = pd.read_excel('constraining_dictionary.xlsx')\n",
    "\n",
    "uncertainity_words = uw_initial.copy()\n",
    "constraining_words = cons_initial.copy()\n",
    "\n",
    "#constraining_words\n",
    "\n",
    "uncertainity_words['Word'] = uncertainity_words['Word'].apply(lambda x: str(x).lower())\n",
    "constraining_words['Word'] = constraining_words['Word'].apply(lambda x: str(x).lower())\n",
    "\n",
    "uncertainity_words = list(uncertainity_words['Word'])\n",
    "constraining_words = list(constraining_words['Word'])\n",
    "\n",
    "#uncertainity_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_whole_report(content):\n",
    "    \n",
    "    new_content = clean(content)\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for i in new_content :\n",
    "        \n",
    "        if i in constraining_words :\n",
    "            \n",
    "            counter += 1\n",
    "            \n",
    "            \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0 \n",
    "\n",
    "mda = defaultdict()\n",
    "qqdmr = defaultdict()\n",
    "rf = default_dict()\n",
    "\n",
    "constraining_words_whole_report = defaultdict()\n",
    "\n",
    "for i in url :\n",
    "    \n",
    "    # 1. getting the content of the url\n",
    "    \n",
    "    response = urllib.request.urlopen(url[i])\n",
    "    raw = response.read().decode('utf8')\n",
    "    \n",
    "    # 2. writing the url content into a file\n",
    "    \n",
    "    with open('content.txt', 'w+') as f:\n",
    "        f.write(raw)\n",
    "\n",
    "    # 3. list of lines\n",
    "    \n",
    "    with open(\"content.txt\",\"r\") as f:\n",
    "        content = f.readlines()\n",
    "        \n",
    "    # 4. making the content into better form\n",
    "    \n",
    "    content = modify_file_content(content)\n",
    "    \n",
    "    # 5. Extract text for each section\n",
    "    \n",
    "    mda[c] = section_content_info(content, sections_patterns[0])\n",
    "    \n",
    "    qqdmr[c] = section_content_info(content, sections_patterns[1])\n",
    "    \n",
    "    #rq[c] = section_content_info(content, sections_patterns[2])\n",
    "    \n",
    "    constraining_words_whole_report[c] = analysis_whole_report(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>OTHER SCORES</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modifying the index of master dictionary\n",
    "\n",
    "md = md.set_index(['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence Number</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>Word Proportion</th>\n",
       "      <th>Average Proportion</th>\n",
       "      <th>Std Dev</th>\n",
       "      <th>Doc Count</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Uncertainty</th>\n",
       "      <th>Litigious</th>\n",
       "      <th>Constraining</th>\n",
       "      <th>Superfluous</th>\n",
       "      <th>Interesting</th>\n",
       "      <th>Modal</th>\n",
       "      <th>Irr_Verb</th>\n",
       "      <th>Harvard_IV</th>\n",
       "      <th>Syllables</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aardvark</th>\n",
       "      <td>1</td>\n",
       "      <td>277</td>\n",
       "      <td>1.480368e-08</td>\n",
       "      <td>1.239377e-08</td>\n",
       "      <td>3.564730e-06</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aardvarks</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.603287e-10</td>\n",
       "      <td>9.725110e-12</td>\n",
       "      <td>9.863549e-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abaci</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4.275431e-10</td>\n",
       "      <td>1.386497e-10</td>\n",
       "      <td>6.225591e-08</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aback</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>6.413147e-10</td>\n",
       "      <td>3.159061e-10</td>\n",
       "      <td>9.383557e-08</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abacus</th>\n",
       "      <td>5</td>\n",
       "      <td>7250</td>\n",
       "      <td>3.874610e-07</td>\n",
       "      <td>3.681624e-07</td>\n",
       "      <td>3.366553e-05</td>\n",
       "      <td>914</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12of12inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sequence Number  Word Count  Word Proportion  Average Proportion  \\\n",
       "Word                                                                          \n",
       "aardvark                 1         277     1.480368e-08        1.239377e-08   \n",
       "aardvarks                2           3     1.603287e-10        9.725110e-12   \n",
       "abaci                    3           8     4.275431e-10        1.386497e-10   \n",
       "aback                    4          12     6.413147e-10        3.159061e-10   \n",
       "abacus                   5        7250     3.874610e-07        3.681624e-07   \n",
       "\n",
       "                Std Dev  Doc Count  Negative  Positive  Uncertainty  \\\n",
       "Word                                                                  \n",
       "aardvark   3.564730e-06         84         0         0            0   \n",
       "aardvarks  9.863549e-09          1         0         0            0   \n",
       "abaci      6.225591e-08          7         0         0            0   \n",
       "aback      9.383557e-08         12         0         0            0   \n",
       "abacus     3.366553e-05        914         0         0            0   \n",
       "\n",
       "           Litigious  Constraining  Superfluous  Interesting  Modal  Irr_Verb  \\\n",
       "Word                                                                            \n",
       "aardvark           0             0            0            0      0         0   \n",
       "aardvarks          0             0            0            0      0         0   \n",
       "abaci              0             0            0            0      0         0   \n",
       "aback              0             0            0            0      0         0   \n",
       "abacus             0             0            0            0      0         0   \n",
       "\n",
       "           Harvard_IV  Syllables     Source  \n",
       "Word                                         \n",
       "aardvark            0          2  12of12inf  \n",
       "aardvarks           0          2  12of12inf  \n",
       "abaci               0          3  12of12inf  \n",
       "aback               0          2  12of12inf  \n",
       "abacus              0          3  12of12inf  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sequence Number', 'Word Count', 'Word Proportion',\n",
       "       'Average Proportion', 'Std Dev', 'Doc Count', 'Negative', 'Positive',\n",
       "       'Uncertainty', 'Litigious', 'Constraining', 'Superfluous',\n",
       "       'Interesting', 'Modal', 'Irr_Verb', 'Harvard_IV', 'Syllables',\n",
       "       'Source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#md.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(words, number_of_sentences):\n",
    "    \n",
    "    negative_score = 0\n",
    "    \n",
    "    positive_score = 0\n",
    "    \n",
    "    complex_word_count = 0\n",
    "    \n",
    "    word_count = len(words)\n",
    "    \n",
    "    word_length = 0\n",
    "    \n",
    "    uncertainty_score = 0\n",
    "    \n",
    "    constraining_score = 0\n",
    "    \n",
    "    for word in words:\n",
    "        \n",
    "        word_length += len(word)\n",
    "        \n",
    "        if md.loc[word, 'Syllables'] >2 :\n",
    "            \n",
    "            complex_word_count +=1\n",
    "        \n",
    "        if md.loc[word, 'Positive'] != 0:\n",
    "            \n",
    "            positive_score += 1\n",
    "        \n",
    "        if md.loc[word, 'Negative'] != 0:\n",
    "            \n",
    "            negative_score += 1\n",
    "    \n",
    "        if word in uncertainity_words:\n",
    "            \n",
    "            uncertainty_score += 1\n",
    "            \n",
    "        if word in constraining_words:\n",
    "            \n",
    "            constraining_score += 1\n",
    "            \n",
    "    polarity_score = (positive_score - negative_score)/((positive_score + negative_score) + 0.000001)\n",
    "    \n",
    "    subjectivity_score = (positive_score + negative_score)/(len(words) + 0.000001)\n",
    "\n",
    "    average_sentence_length = len(words)/number_of_sentences\n",
    "    \n",
    "    percentage_of_complex_words = complex_word_count / len(words)\n",
    "    \n",
    "    fog_index = (0.4)*(average_sentence_length + percentage_of_complex_words)\n",
    "    \n",
    "    average_word_length = word_length / len(words)\n",
    "    \n",
    "    positive_word_proportion = positive_score / word_count\n",
    "    \n",
    "    negative_word_proportion = negative_score / word_count\n",
    "    \n",
    "    uncertainty_word_proportion = uncertainty_score / word_count\n",
    "    \n",
    "    constraining_word_proportion = constraining_score / words_count\n",
    "    \n",
    "    return (positive_score, \n",
    "            negative_score, \n",
    "            average_sentence_length, \n",
    "            percentage_of_complex_words, \n",
    "            fog_index, \n",
    "            complex_word_count,\n",
    "            word_count,\n",
    "            uncertainty_score,\n",
    "            constraining_score,\n",
    "            positive_word_proportion,\n",
    "            negative_word_proportion,\n",
    "            uncertainty_word_proportion,\n",
    "            constraining_word_proportion\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_variables():\n",
    "    \n",
    "    for i in mda.keys():\n",
    "        (mda_positive_score[i],\n",
    "        mda_negative_score[i],\n",
    "        mda_polarity_score[i],\n",
    "        mda_average_sentence_length[i],\n",
    "        mda_percentage_of_complex_words[i],\n",
    "        mda_fog_index[i],\n",
    "        mda_complex_word_count[i],\n",
    "        mda_word_count[i],\n",
    "        mda_uncertainty_score[i],\n",
    "        mda_constraining_score[i],\n",
    "        mda_positive_word_proportion[i],\n",
    "        mda_negative_word_proportion[i],\n",
    "        mda_uncertainty_word_proportion[i],\n",
    "        mda_constraining_word_proportion[i]) = scores(mda[i])\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = urllib.request.urlopen(url)\n",
    "\n",
    "raw = response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local_filename, headers = urllib.request.urlretrieve('https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-000413.txt')\n",
    "# html = open(local_filename).decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sections = [\"Management's Discussion and Analysis\", \"Quantitative and Qualitative Disclosures about Market Risk\", \"Risk Factors\"]\n",
    "\n",
    "# z = html.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f= open(\"temp.txt\",\"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.write(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('temp.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "# print(f[:-1])\n",
    "        \n",
    "# f = open('temp_file.txt', 'w')\n",
    "\n",
    "# f.write(z)\n",
    "\n",
    "# k = open('temp_file.txt', 'r')\n",
    "\n",
    "# k.readlines(1)\n",
    "\n",
    "# k.close()\n",
    "\n",
    "# f.close()\n",
    "    \n",
    "#     print(type(html))\n",
    "            \n",
    "#     with html as fileinput:\n",
    "        \n",
    "#         print(fileinput)\n",
    "        \n",
    "#         exit\n",
    "        \n",
    "#         for line in fileinput:\n",
    "            \n",
    "#             line = line.lower()\n",
    "        \n",
    "#         if '\\n' in  fileinput:\n",
    "            \n",
    "#             print('yes')\n",
    "\n",
    "# f.close()\n",
    "\n",
    "# f = open('temp_file.txt' 'r')\n",
    "\n",
    "# f.read()\n",
    "\n",
    "# f.close()\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.sec.gov/Archives/edgar/data/3662/0000950170-98-000413.txt\"\n",
    "response = urllib.request.urlopen(url)\n",
    "raw = response.read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex = r\"(?<=ITEM\\s\\d\\.\\sMANAGEMENT\\'S\\sDISCUSSION\\sAND\\sANALYSIS\\sOF\\sFINANCIAL\\sCONDITION\\sAND\\sRESULTS\\sOF\\sOPERATION)(.*?)(?=ITEM\\s\\d\\.\\s)\"\n",
    "\n",
    "#test_str = (\"ITEM 7. MANAGEMENT'S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATION \\nkdfoks[dlsaf;\\nsd\\nlgsld\\ns['a\\n'[df\\na'fd\\nsaD\\FSAD\\nfF\\n ITEM 8. dhfkjskaskdkskd\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.findall(regex, test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(l)):\n",
    "    l[i] = l[i].replace('\\n', ' ')\n",
    "    l[i] = l[i].replace('\\\\', '')\n",
    "    l[i] = l[i].replace('\\t', ' ')\n",
    "    l[i] = l[i].replace(\"\\'\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_str = ' '.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern = r'''(?<=ITEM\\s\\d\\.\\sMANAGEMENTS\\sDISCUSSION\\sAND\\sANALYSIS\\sOF\\sFINANCIAL\\sCONDITION\\sAND\\sRESULTS\\sOF\\sOPERATION)(.*?)(?=ITEM\\s\\d\\.\\s)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'''(ITEM\\s\\d\\.\\sMANAGEMENTS\\sDISCUSSION\\sAND\\sANALYSIS\\sOF\\sFINANCIAL\\sCONDITION\\sAND\\sRESULTS)(.*?)(ITEM\\s\\d\\.\\s)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_list = re.findall(pattern, new_str, re.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = new_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_text = re.sub(r'\\s+', r' ', final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = re.sub(r\"(<.*>)\",r\" \",final_text).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = re.sub(\"[^a-zA-Z]\",\" \",final_text).lower()\n",
    "\n",
    "final_text\n",
    "\n",
    "final_text = re.sub(r'\\s+', r' ', final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_stop_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "stop_word_file_path = '/home/pramila/Desktop/CLASSWORK/ML-ASGN-BLACKCOFFER/blackcoffer assignment/STOP-WORDS/'\n",
    "\n",
    "list_of_files = os.listdir(stop_word_file_path)\n",
    "\n",
    "#2\n",
    "for i in list_of_files:\n",
    "    \n",
    "    with open(os.path.join(stop_word_file_path, i), 'r') as words :\n",
    "        \n",
    "        content = words.read()\n",
    "        \n",
    "        with open('stop_words.txt', 'a+') as stop_words :\n",
    "            \n",
    "            stop_words.write(content + '\\n')\n",
    "            \n",
    "            \n",
    "#3\n",
    "with open('stop_words.txt', 'r') as stop_words :\n",
    "            \n",
    "            list_of_stop_words = stop_words.readlines()\n",
    "\n",
    "#list_of_stop_words\n",
    "\n",
    "#some modification req in stop_words_list\n",
    "\n",
    "for i in range(len(list_of_stop_words)) :\n",
    "    \n",
    "    list_of_stop_words[i] = list_of_stop_words[i].replace('\\n', \"\").lower()\n",
    "\n",
    "\n",
    "list_of_stop_words = list(set(list_of_stop_words))\n",
    "\n",
    "list_of_stop_words.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if polarity_score < -0.5 :\n",
    "        \n",
    "        sentiment_score_categorization = 'Most Negative'\n",
    "        \n",
    "    elif (polarity_score < 0) and (polarity_score > -0.5):\n",
    "        \n",
    "        sentiment_score_categorization = 'Negative'\n",
    "        \n",
    "    elif polarity_score == 0:\n",
    "        \n",
    "        sentiment_score_categorization = 'Neutral'\n",
    "        \n",
    "    elif (polarity_score > 0) and (polarity_score < 0.5):\n",
    "        \n",
    "        sentiment_score_categorization = 'Positive'\n",
    "        \n",
    "    elif polarity_score > 0.5:\n",
    "        \n",
    "        sentiment_score_categorization = 'Very Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_stop_words(content):\n",
    "#     new_content = content\n",
    "#     print(len(content))\n",
    "    \n",
    "#     print(\"\\n\")\n",
    "#     for i in range(len(content)):\n",
    "#         print(i)\n",
    "        \n",
    "#         if content[i] in li1:\n",
    "        \n",
    "#             del new_content[i]\n",
    "            \n",
    "#         elif content[i] in li2:\n",
    "            \n",
    "#             del new_content[i]\n",
    "            \n",
    "#         elif content[i] in li3:\n",
    "            \n",
    "#             del new_content[i]\n",
    "            \n",
    "#         elif content[i] in li4:\n",
    "            \n",
    "#             del new_content[i]\n",
    "            \n",
    "#     return new_content\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_string = \" \".join(list_of_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = re.split(r' ', final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text = set(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import master dictionary\n",
    "\n",
    "# master_dict_ini = pd.read_excel('LoughranMcDonald_MasterDictionary_2018.xlsx')\n",
    "\n",
    "# md = master_dict_ini.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       86132\n",
       "2009      352\n",
       "2012        1\n",
       "2011        1\n",
       "Name: Positive, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md['Positive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       84131\n",
       "2009     2315\n",
       "2014       26\n",
       "2011       13\n",
       "2012        1\n",
       "Name: Negative, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md['Negative'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12of12inf    81536\n",
       "10K_2010      1898\n",
       "2018          1265\n",
       "10K_2008       871\n",
       "10K_2014       462\n",
       "10K_2012       339\n",
       "10K_2016        90\n",
       "10K_2009        14\n",
       "10K_2011        11\n",
       "Name: Source, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md['Source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentences = 'A Turning machine is a device that manipulates symbols on a strip of tape according to a table of rules. Despite its simplicity, a Turing machine can be adapted to simulate the logic of any computer algorithm, and is particularly useful in explaining the functions of a CPU.... inside a computer. The \"Turing\" machine was described by Alan Turing in 1936, who called it an \"a(utomatic)-machine\". The Turing machine is not intended as a practical computing technology, but rather as a hypothetical device representing a computing machine. Turing machines help computer scientists understand the limits of mechaniacl computation.'\n",
    "\n",
    "number_of_sentences = sent_tokenize(sentences)\n",
    "\n",
    "print(len(number_of_sentences))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
